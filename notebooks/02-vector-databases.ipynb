{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e89c5b3",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/tapi-logo-small.png\" />\n",
    "\n",
    "This notebook free for educational reuse under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Created by [Firstname Lastname](https://) for the 2024 Text Analysis Pedagogy Institute, with support from [Constellate](https://constellate.org).\n",
    "\n",
    "For questions/comments/improvements, email author@email.address.<br />\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f932d1",
   "metadata": {},
   "source": [
    "# `Introduction to Semantic Search and Vector Databases` `1`\n",
    "\n",
    "This is lesson `2` of 3 in the educational series on `Semantic Search and Vector Databases`. This notebook is intended `to teach the basic concepts of vector databases`.\n",
    "\n",
    "**Skills:** \n",
    "* Data analysis\n",
    "* Machine learning\n",
    "* Text analysis\n",
    "* spaCy\n",
    "* Vector databases\n",
    "* Semantic search\n",
    "* Python\n",
    "\n",
    "**Audience:** `Teachers` / `Learners` / `Researchers`\n",
    "\n",
    "**Use case:** `Tutorial` / `How-To` / `Explanation` \n",
    "\n",
    "`Include the use case definition from [here](https://constellate.org/docs/documentation-categories)`\n",
    "\n",
    "**Difficulty:** `Intermediate`\n",
    "\n",
    "`Beginner assumes users are relatively new to Python and Jupyter Notebooks. The user is helped step-by-step with lots of explanatory text.`\n",
    "`Intermediate assumes users are familiar with Python and have been programming for 6+ months. Code makes up a larger part of the notebook and basic concepts related to Python are not explained.`\n",
    "`Advanced assumes users are very familiar with Python and have been programming for years, but they may not be familiar with the process being explained.`\n",
    "\n",
    "**Completion time:** `90 minutes`\n",
    "\n",
    "**Knowledge Required:** \n",
    "```\n",
    "* Python basics (variables, flow control, functions, lists, dictionaries)\n",
    "* Object-oriented programming (classes, instances, inheritance)\n",
    "* Regular Expressions (`re`, character classes)\n",
    "\n",
    "These should be general skills but can mention a particular library\n",
    "```\n",
    "\n",
    "**Knowledge Recommended:**\n",
    "```\n",
    "* Basic file operations (open, close, read, write)\n",
    "* Data cleaning with `Pandas`\n",
    "```\n",
    "\n",
    "**Learning Objectives:**\n",
    "After this lesson, learners will be able to:\n",
    "```\n",
    "1. Learn how to create a normal search engine with Python using best match 25 (BM25)\n",
    "2. Learn about vector databases\n",
    "3. Learn about creating a basic vector database with Annoy\n",
    "4. Learn how to query a vectory database with Annoy\n",
    "```\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c0555",
   "metadata": {},
   "source": [
    "# Required Python Libraries\n",
    "`List out any libraries used and what they are used for`\n",
    "* spacy for tokenization and sentence chunking\n",
    "* srsly for loading json data\n",
    "* annoy for creating a vector database\n",
    "* txtai (for outside of class work)\n",
    "* sentence-transformers for loading a model and encoding texts\n",
    "* pandas for working withd ata\n",
    "\n",
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e8a220f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (3.7.5)\n",
      "Requirement already satisfied: scikit-learn in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: srsly in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (2.4.8)\n",
      "Requirement already satisfied: annoy in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (1.17.3)\n",
      "Requirement already satisfied: txtai in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (7.3.0)\n",
      "Requirement already satisfied: sentence-transformers in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: pandas in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (2.2.2)\n",
      "Collecting rank-bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: faiss-cpu>=1.7.1.post2 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from txtai) (1.8.0.post1)\n",
      "Requirement already satisfied: torch>=1.12.1 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from txtai) (2.3.1)\n",
      "Requirement already satisfied: transformers>=4.28.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from txtai) (4.36.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.9.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from txtai) (0.23.4)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from txtai) (6.0.1)\n",
      "Requirement already satisfied: regex>=2022.8.17 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from txtai) (2024.5.15)\n",
      "Requirement already satisfied: Pillow in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: filelock in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from huggingface-hub>=0.9.0->txtai) (4.12.2)\n",
      "Requirement already satisfied: language-data>=1.2 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: sympy in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from torch>=1.12.1->txtai) (1.13.0)\n",
      "Requirement already satisfied: networkx in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from torch>=1.12.1->txtai) (3.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from transformers>=4.28.0->txtai) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from transformers>=4.28.0->txtai) (0.4.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from sympy->torch>=1.12.1->txtai) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Applications/anaconda3/envs/tap/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank-bm25\n",
      "Successfully installed rank-bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "### Install Libraries ###\n",
    "\n",
    "# Using !pip installs\n",
    "!pip install spacy scikit-learn srsly annoy txtai sentence-transformers pandas rank-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5480e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "from annoy import AnnoyIndex\n",
    "import spacy\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dedd148",
   "metadata": {},
   "source": [
    "# Required Data\n",
    "\n",
    "For this lesson, we are working with a small sample from the Founders Online archive. If you would like to work with a larger sample, I have provided the scripts necessary for using the `metadata.json` provided by Founders Online to download a sample from their website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53edaa2",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we will build on the concepts we learned in the first notebook. In the first notebook, we learned about the fundamental concepts being vector databases and semantic searching, that is vectorization itself and doing so with various types of machine learning models. We learned that transformers are best suited for this particular problem because they produce dynamic vectors, rather than static vectors. Dynamic vectors allow for a given token's vector to change depending on context.\n",
    "\n",
    "In this notebook, we will use this knowledge to create our first vector database and even query it semantically! It is important to note that while the work in this notebook produces good results, this is not what you would do should you wish to build a formal project. A formal project will often use a cloud-based solution and a proper server. We will cover these steps in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681373e7",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "\n",
    "To create a vector database, you must start with data. We will be working with data from [Founders Online](https://founders.archives.gov/). This data is available in the `../data/processed/` folder. I have provided us with a sample of 10, 100, and 1,000. For this notebook, we will be working with a sample of 1,000. It is important to note that I have seeded the random sample. This means that the data you work with each time will be the same. To get different data, change the seed of the script, located in `./src/data/` called `download_data.py`.\n",
    "\n",
    "This data is a collection of writings of the Founders. The data is useful for doing social network analysis as many of the writings are letters. It's also useful for mapping writings across time and space as many of the writings are dated and contain information about specific locations. For our purposes, however, we will be working with the main content of the letters to create a vector database. \n",
    "\n",
    "To get started, let's load the data. We will be using `srsly`. I'm including this in this tutorial as a way to introduce students to the library. You can also use the standard `json` package here. `srsly` has a few advantages, namely it loads the data as a generator. This is useful when you start working with larger datasets (as you typically do with vector databases) because the entire dataset is not loaded into memory at once. Because of this, though, we want to convert it to a list just to make it a bit easier to use for our purposes, so when loading the data, we convert it to a list with the `list()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15e4ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(srsly.read_json(\"../data/processed/sample_1000_42.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7df1b",
   "metadata": {},
   "source": [
    "Now that we have loaded up our data, let's take a brief look at it by examining the first index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb544513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Thomas Jefferson to Joseph Milligan, 22 December 1815',\n",
       " 'permalink': 'https://founders.archives.gov/documents/Jefferson/03-09-02-0174',\n",
       " 'project': 'Jefferson Papers',\n",
       " 'authors': ['Jefferson, Thomas'],\n",
       " 'recipients': ['Milligan, Joseph'],\n",
       " 'date-from': '1815-12-22',\n",
       " 'date-to': '1815-12-22',\n",
       " 'content': 'Monticello Dec. 22. 15.\\nDear Sir\\nOn my return here from Bedford a few days ago, I found the Hutton and Requisite tables, bound to my mind. by this mail I send you an Ovid’s metamorphoses almost entirely worne out & defaced, yet of sovaluable and rareaneditionthat I wish you to put it into as good a state of repair as it is susceptible of. by the next mail I will forward a Cornelius Nepos to be bound. be so good as to procure and forward to me by stage the underwritten books.I salute you with friendship & esteem\\nTh: Jefferson\\nAinsworth’sLat. & Eng. dict. abridged. to be bound[. . .]\\nthe Lat. & Eng in one, & the Eng. & Lat.[. . .]\\nOvid’s metamorphoses. the Delphin edn in 8vo\\nCornelius Nepos. the Delphin edn if to be had; if not some other good one.\\nVirgil. the Delphin edn lately printed in Phil. with English notes.\\nMair’s Tyro’s dictionary.\\nI observe a mrRichardsonadvertises in the National Intelligencer the Scientific dialogues: if the edition be compleat comprehending theChemical part, I should be glad to have it'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74370a",
   "metadata": {},
   "source": [
    "Notice that we have some important metadata here including the title, permalink (link to the website where this particular entry appears), project, authors, recipients, date-from, date-to, and content. Everything here is as presented in the original metadata.json file with the exception of `content`. I have added this after pulling the data from the website. We will learn about how we can make these extra attributes more useful in the next notebook. For now, let's focus on the `content` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8ac54164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monticello Dec. 22. 15.\n",
      "Dear Sir\n",
      "On my return here from Bedford a few days ago, I found the Hutton and Requisite tables, bound to my mind. by this mail I send you an Ovid’s metamorphoses almost entirely worne out & defaced, yet of sovaluable and rareaneditionthat I wish you to put it into as good a state of repair as it is susceptible of. by the next mail I will forward a Cornelius Nepos to be bound. be so good as to procure and forward to me by stage the underwritten books.I salute you with friendship & esteem\n",
      "Th: Jefferson\n",
      "Ainsworth’sLat. & Eng. dict. abridged. to be bound[. . .]\n",
      "the Lat. & Eng in one, & the Eng. & Lat.[. . .]\n",
      "Ovid’s metamorphoses. the Delphin edn in 8vo\n",
      "Cornelius Nepos. the Delphin edn if to be had; if not some other good one.\n",
      "Virgil. the Delphin edn lately printed in Phil. with English notes.\n",
      "Mair’s Tyro’s dictionary.\n",
      "I observe a mrRichardsonadvertises in the National Intelligencer the Scientific dialogues: if the edition be compleat comprehending theChemical part, I should be glad to have it\n"
     ]
    }
   ],
   "source": [
    "print(data[0][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26afe1c",
   "metadata": {},
   "source": [
    "This gives us a better sense of this letter. As we can see this is a raw-string representation of the data. The odd formatting is due to how the data is rendered on the main page, likely to capture the structure of the original document. If you want to verify what the original document looks like, use the link below. Here is what it looks like as of the writing of this notebook.\n",
    "\n",
    "![founders](../assets/founders.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "879add87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://founders.archives.gov/documents/Jefferson/03-09-02-0174\n"
     ]
    }
   ],
   "source": [
    "print(data[0][\"permalink\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653117c4",
   "metadata": {},
   "source": [
    "# Vectorizing Documents\n",
    "\n",
    "Now that we have all our documents, it comes time to vectorize them, or convert them into a sequence of vectors. This is where we pass the texts to a machine learning model and capture the output vector for each of them. To do this, though, we need a model loaded. We will be using the `sentence-transformers` library. It makes this process as simple as possible with only two lines of code. First, we will need to load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ef8f6667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/tap/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # This is a standard, efficient model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2efbba5",
   "metadata": {},
   "source": [
    "Now that we have loaded our model we can (optionally) specify the specific device. The code below will put it onto your GPU, if available. If you don't know if this is enabled on your device, then it likely is not. The steps to activate `cuda` are very specific and require you to install certain packages in a certain way. If you do not have cuda, then the default will be the `cpu`. With 1,000 documents, this will not be an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c2eb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51703f34",
   "metadata": {},
   "source": [
    "Now that we have our model loaded, we need to get just the texts from all our data, we can do that with list comprehension or we can use more verbose code. I'll provide both here. Note, both approaches are perfectly fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a803fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = [item[\"content\"] for item in data]\n",
    "\n",
    "texts = []\n",
    "for item in data:\n",
    "    texts.append(item[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec33ab1",
   "metadata": {},
   "source": [
    "Let's take a look at the new data we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9aa4a23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monticello Dec. 22. 15.\\nDear Sir\\nOn my return here from Bedford a few days ago, I found the Hutton and Requisite tables, bound to my mind. by this mail I send you an Ovid’s metamorphoses almost entirely worne out & defaced, yet of sovaluable and rareaneditionthat I wish you to put it into as good a state of repair as it is susceptible of. by the next mail I will forward a Cornelius Nepos to be bound. be so good as to procure and forward to me by stage the underwritten books.I salute you with friendship & esteem\\nTh: Jefferson\\nAinsworth’sLat. & Eng. dict. abridged. to be bound[. . .]\\nthe Lat. & Eng in one, & the Eng. & Lat.[. . .]\\nOvid’s metamorphoses. the Delphin edn in 8vo\\nCornelius Nepos. the Delphin edn if to be had; if not some other good one.\\nVirgil. the Delphin edn lately printed in Phil. with English notes.\\nMair’s Tyro’s dictionary.\\nI observe a mrRichardsonadvertises in the National Intelligencer the Scientific dialogues: if the edition be compleat comprehending theChemical part, I should be glad to have it',\n",
       " '[Baltimore] 3 May 1791.\\nMy dear Sir.\\nI did not receive your letter of the 26th till the morning of the 2d. I immediately after saw Gen. Williams and made such communication of your wishes as I thought most likely to be attended with success. You know his ambitious cast, and that he thinks he could be more serviceable at the head of a great department than collector of a district. I mentioned the death of the comptroller, and the probability inmy opinionthat the President from the knowlege he had of the present auditors habits experience and capacities for business would fix upon him for a successor; in which case the auditorship which was a very important office would become vacant. I observed on the advantages of a residence at the seat of Congress if he still inclined to mount higher, that he knew your power and disposition, and said I would take upon myself to make the necessary suggestions. The idea of the auditors office being a step to a still more desirable one had its weight, but he finally declined, alledging his ill state of health, and the recent death of a brother in law Col. Stull which has devolved upon him the care of his children and estate. In short he was not to be induced to be auditor, tho’ I thought could I have said comptrouller he might, notwithstanding his present state of health would unfit him for discharging the duties of either.\\nI then called on Mr. Wm. Smith who with less shew of talentswill make a much better auditor. He will have as little to learn as the General; is as systematic, a more correct and perfect accountant, of great respectability and of longer standing in society. I found also here that the comptrollership was a more darling object. My first conversation was yesterday, and it was not till about half an hour ago I got him to consent to use my discretion, so you may use yours. I was obliged to intimate, that from the opinion you had of him, I could entertain no doubt but his appointment would be certain unless the President got entangled to the Southward.\\nYou judged right. Nay, should even what I once thought of take place, and my present temper of mind continue, I would remain where I am. My mind in the loss of a brother has received a severe shock. My wife like yours is every thing that is kind good and excellent, and was there only one man more in the world I should be the happiest man in it.\\nAdieu and believe me yours most sincerely and most affectionately\\nJames McHenry']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c5fd9d",
   "metadata": {},
   "source": [
    "As we can see `texts` now corresponds to a list of each of our texts. We should have 1,000 of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d50a1820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47777a31",
   "metadata": {},
   "source": [
    "Now that we have all our texts, let's encode them! We can do that with a single line. I like to set `show_progress_bar` to `True`. This allows me to see how long things take on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b6d9b848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf9a22e08e04b04b59321bf540a984a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = model.encode(texts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda52b0",
   "metadata": {},
   "source": [
    "With our embeddings now created, let's convert our original dataset into a `Pandas` DataFrame. This will make it just a bit easier to visualize and work with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca21712c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>permalink</th>\n",
       "      <th>project</th>\n",
       "      <th>authors</th>\n",
       "      <th>recipients</th>\n",
       "      <th>date-from</th>\n",
       "      <th>date-to</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thomas Jefferson to Joseph Milligan, 22 Decemb...</td>\n",
       "      <td>https://founders.archives.gov/documents/Jeffer...</td>\n",
       "      <td>Jefferson Papers</td>\n",
       "      <td>[Jefferson, Thomas]</td>\n",
       "      <td>[Milligan, Joseph]</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>Monticello Dec. 22. 15.\\nDear Sir\\nOn my retur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To Alexander Hamilton from James McHenry, 3 Ma...</td>\n",
       "      <td>https://founders.archives.gov/documents/Hamilt...</td>\n",
       "      <td>Hamilton Papers</td>\n",
       "      <td>[McHenry, James]</td>\n",
       "      <td>[Hamilton, Alexander]</td>\n",
       "      <td>1791-05-03</td>\n",
       "      <td>1791-05-03</td>\n",
       "      <td>[Baltimore] 3 May 1791.\\nMy dear Sir.\\nI did n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Adams to John Quincy Adams and Thomas Boy...</td>\n",
       "      <td>https://founders.archives.gov/documents/Adams/...</td>\n",
       "      <td>Adams Papers</td>\n",
       "      <td>[Adams, John]</td>\n",
       "      <td>[Adams, John Quincy, Adams, Thomas Boylston]</td>\n",
       "      <td>1794-09-14</td>\n",
       "      <td>1794-09-14</td>\n",
       "      <td>Quincy Septr.14. 1794\\nMy dear Sons\\nI once mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From George Washington to Major General Horati...</td>\n",
       "      <td>https://founders.archives.gov/documents/Washin...</td>\n",
       "      <td>Washington Papers</td>\n",
       "      <td>[Washington, George]</td>\n",
       "      <td>[Gates, Horatio]</td>\n",
       "      <td>1776-12-23</td>\n",
       "      <td>1776-12-23</td>\n",
       "      <td>Head Quarters [Bucks County, Pa.] 23d Decr 177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Diary entry: 5 July 1795]</td>\n",
       "      <td>https://founders.archives.gov/documents/Washin...</td>\n",
       "      <td>Washington Papers</td>\n",
       "      <td>[Washington, George]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1795-07-05</td>\n",
       "      <td>1795-07-05</td>\n",
       "      <td>Could not find the main content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>From John Adams to Boston Patriot, 4 November ...</td>\n",
       "      <td>https://founders.archives.gov/documents/Adams/...</td>\n",
       "      <td>Adams Papers</td>\n",
       "      <td>[Adams, John]</td>\n",
       "      <td>[Boston Patriot]</td>\n",
       "      <td>1809-11-04</td>\n",
       "      <td>1809-11-04</td>\n",
       "      <td>Quincy, November 4, 1809.\\nSirs,\\nIn my last l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>From John Adams to United States Senate, 14 Ma...</td>\n",
       "      <td>https://founders.archives.gov/documents/Adams/...</td>\n",
       "      <td>Adams Papers</td>\n",
       "      <td>[Adams, John]</td>\n",
       "      <td>[United States Senate]</td>\n",
       "      <td>1798-03-14</td>\n",
       "      <td>1798-03-14</td>\n",
       "      <td>United States March 14th 1798:\\nGentlemen of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>To Benjamin Franklin from William Henly, [Apri...</td>\n",
       "      <td>https://founders.archives.gov/documents/Frankl...</td>\n",
       "      <td>Franklin Papers</td>\n",
       "      <td>[Henly, William]</td>\n",
       "      <td>[Franklin, Benjamin]</td>\n",
       "      <td>1772-04-01</td>\n",
       "      <td>1772-04-30</td>\n",
       "      <td>Sunday Eve. [April?, 1772]\\nDear Sir:\\nI have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>From George Washington to Major General Alexan...</td>\n",
       "      <td>https://founders.archives.gov/documents/Washin...</td>\n",
       "      <td>Washington Papers</td>\n",
       "      <td>[Washington, George]</td>\n",
       "      <td>[McDougall, Alexander]</td>\n",
       "      <td>1779-05-20</td>\n",
       "      <td>1779-05-20</td>\n",
       "      <td>Head Quarters Middle Brook May 20th 1779\\nDr S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>From Thomas Jefferson to João, Prince Regent o...</td>\n",
       "      <td>https://founders.archives.gov/documents/Jeffer...</td>\n",
       "      <td>Jefferson Papers</td>\n",
       "      <td>[Jefferson, Thomas]</td>\n",
       "      <td>[João, Prince Regent of Portugal]</td>\n",
       "      <td>1801-10-12</td>\n",
       "      <td>1801-10-12</td>\n",
       "      <td>To our Great and Good Friend, His Royal Highne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Thomas Jefferson to Joseph Milligan, 22 Decemb...   \n",
       "1    To Alexander Hamilton from James McHenry, 3 Ma...   \n",
       "2    John Adams to John Quincy Adams and Thomas Boy...   \n",
       "3    From George Washington to Major General Horati...   \n",
       "4                           [Diary entry: 5 July 1795]   \n",
       "..                                                 ...   \n",
       "995  From John Adams to Boston Patriot, 4 November ...   \n",
       "996  From John Adams to United States Senate, 14 Ma...   \n",
       "997  To Benjamin Franklin from William Henly, [Apri...   \n",
       "998  From George Washington to Major General Alexan...   \n",
       "999  From Thomas Jefferson to João, Prince Regent o...   \n",
       "\n",
       "                                             permalink            project  \\\n",
       "0    https://founders.archives.gov/documents/Jeffer...   Jefferson Papers   \n",
       "1    https://founders.archives.gov/documents/Hamilt...    Hamilton Papers   \n",
       "2    https://founders.archives.gov/documents/Adams/...       Adams Papers   \n",
       "3    https://founders.archives.gov/documents/Washin...  Washington Papers   \n",
       "4    https://founders.archives.gov/documents/Washin...  Washington Papers   \n",
       "..                                                 ...                ...   \n",
       "995  https://founders.archives.gov/documents/Adams/...       Adams Papers   \n",
       "996  https://founders.archives.gov/documents/Adams/...       Adams Papers   \n",
       "997  https://founders.archives.gov/documents/Frankl...    Franklin Papers   \n",
       "998  https://founders.archives.gov/documents/Washin...  Washington Papers   \n",
       "999  https://founders.archives.gov/documents/Jeffer...   Jefferson Papers   \n",
       "\n",
       "                  authors                                    recipients  \\\n",
       "0     [Jefferson, Thomas]                            [Milligan, Joseph]   \n",
       "1        [McHenry, James]                         [Hamilton, Alexander]   \n",
       "2           [Adams, John]  [Adams, John Quincy, Adams, Thomas Boylston]   \n",
       "3    [Washington, George]                              [Gates, Horatio]   \n",
       "4    [Washington, George]                                            []   \n",
       "..                    ...                                           ...   \n",
       "995         [Adams, John]                              [Boston Patriot]   \n",
       "996         [Adams, John]                        [United States Senate]   \n",
       "997      [Henly, William]                          [Franklin, Benjamin]   \n",
       "998  [Washington, George]                        [McDougall, Alexander]   \n",
       "999   [Jefferson, Thomas]             [João, Prince Regent of Portugal]   \n",
       "\n",
       "      date-from     date-to                                            content  \n",
       "0    1815-12-22  1815-12-22  Monticello Dec. 22. 15.\\nDear Sir\\nOn my retur...  \n",
       "1    1791-05-03  1791-05-03  [Baltimore] 3 May 1791.\\nMy dear Sir.\\nI did n...  \n",
       "2    1794-09-14  1794-09-14  Quincy Septr.14. 1794\\nMy dear Sons\\nI once mo...  \n",
       "3    1776-12-23  1776-12-23  Head Quarters [Bucks County, Pa.] 23d Decr 177...  \n",
       "4    1795-07-05  1795-07-05                    Could not find the main content  \n",
       "..          ...         ...                                                ...  \n",
       "995  1809-11-04  1809-11-04  Quincy, November 4, 1809.\\nSirs,\\nIn my last l...  \n",
       "996  1798-03-14  1798-03-14  United States March 14th 1798:\\nGentlemen of t...  \n",
       "997  1772-04-01  1772-04-30  Sunday Eve. [April?, 1772]\\nDear Sir:\\nI have ...  \n",
       "998  1779-05-20  1779-05-20  Head Quarters Middle Brook May 20th 1779\\nDr S...  \n",
       "999  1801-10-12  1801-10-12  To our Great and Good Friend, His Royal Highne...  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62faba",
   "metadata": {},
   "source": [
    "Now that we have loaded our data, let's add the embeddings into our DataFrame. To do that, we can convert our embeddings to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b3d0de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embedding\"] = list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a5b97374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>permalink</th>\n",
       "      <th>project</th>\n",
       "      <th>authors</th>\n",
       "      <th>recipients</th>\n",
       "      <th>date-from</th>\n",
       "      <th>date-to</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thomas Jefferson to Joseph Milligan, 22 Decemb...</td>\n",
       "      <td>https://founders.archives.gov/documents/Jeffer...</td>\n",
       "      <td>Jefferson Papers</td>\n",
       "      <td>[Jefferson, Thomas]</td>\n",
       "      <td>[Milligan, Joseph]</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>Monticello Dec. 22. 15.\\nDear Sir\\nOn my retur...</td>\n",
       "      <td>[-0.11585674, -0.031811118, 0.054534256, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To Alexander Hamilton from James McHenry, 3 Ma...</td>\n",
       "      <td>https://founders.archives.gov/documents/Hamilt...</td>\n",
       "      <td>Hamilton Papers</td>\n",
       "      <td>[McHenry, James]</td>\n",
       "      <td>[Hamilton, Alexander]</td>\n",
       "      <td>1791-05-03</td>\n",
       "      <td>1791-05-03</td>\n",
       "      <td>[Baltimore] 3 May 1791.\\nMy dear Sir.\\nI did n...</td>\n",
       "      <td>[-0.077039875, 0.06889965, 0.05614029, -0.0018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Adams to John Quincy Adams and Thomas Boy...</td>\n",
       "      <td>https://founders.archives.gov/documents/Adams/...</td>\n",
       "      <td>Adams Papers</td>\n",
       "      <td>[Adams, John]</td>\n",
       "      <td>[Adams, John Quincy, Adams, Thomas Boylston]</td>\n",
       "      <td>1794-09-14</td>\n",
       "      <td>1794-09-14</td>\n",
       "      <td>Quincy Septr.14. 1794\\nMy dear Sons\\nI once mo...</td>\n",
       "      <td>[-0.13977431, 0.04176549, 0.06941472, -0.06869...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From George Washington to Major General Horati...</td>\n",
       "      <td>https://founders.archives.gov/documents/Washin...</td>\n",
       "      <td>Washington Papers</td>\n",
       "      <td>[Washington, George]</td>\n",
       "      <td>[Gates, Horatio]</td>\n",
       "      <td>1776-12-23</td>\n",
       "      <td>1776-12-23</td>\n",
       "      <td>Head Quarters [Bucks County, Pa.] 23d Decr 177...</td>\n",
       "      <td>[0.006098511, 0.048442684, 0.046325486, -0.071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Diary entry: 5 July 1795]</td>\n",
       "      <td>https://founders.archives.gov/documents/Washin...</td>\n",
       "      <td>Washington Papers</td>\n",
       "      <td>[Washington, George]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1795-07-05</td>\n",
       "      <td>1795-07-05</td>\n",
       "      <td>Could not find the main content</td>\n",
       "      <td>[0.041819364, -0.009509875, -0.019032704, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>From John Adams to Boston Patriot, 4 November ...</td>\n",
       "      <td>https://founders.archives.gov/documents/Adams/...</td>\n",
       "      <td>Adams Papers</td>\n",
       "      <td>[Adams, John]</td>\n",
       "      <td>[Boston Patriot]</td>\n",
       "      <td>1809-11-04</td>\n",
       "      <td>1809-11-04</td>\n",
       "      <td>Quincy, November 4, 1809.\\nSirs,\\nIn my last l...</td>\n",
       "      <td>[-0.026789177, -0.004801429, 0.06341488, -0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>From John Adams to United States Senate, 14 Ma...</td>\n",
       "      <td>https://founders.archives.gov/documents/Adams/...</td>\n",
       "      <td>Adams Papers</td>\n",
       "      <td>[Adams, John]</td>\n",
       "      <td>[United States Senate]</td>\n",
       "      <td>1798-03-14</td>\n",
       "      <td>1798-03-14</td>\n",
       "      <td>United States March 14th 1798:\\nGentlemen of t...</td>\n",
       "      <td>[-0.08672993, 0.036208663, 0.036546204, -0.038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>To Benjamin Franklin from William Henly, [Apri...</td>\n",
       "      <td>https://founders.archives.gov/documents/Frankl...</td>\n",
       "      <td>Franklin Papers</td>\n",
       "      <td>[Henly, William]</td>\n",
       "      <td>[Franklin, Benjamin]</td>\n",
       "      <td>1772-04-01</td>\n",
       "      <td>1772-04-30</td>\n",
       "      <td>Sunday Eve. [April?, 1772]\\nDear Sir:\\nI have ...</td>\n",
       "      <td>[-0.06445475, 0.060675066, 0.07255046, 0.07447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>From George Washington to Major General Alexan...</td>\n",
       "      <td>https://founders.archives.gov/documents/Washin...</td>\n",
       "      <td>Washington Papers</td>\n",
       "      <td>[Washington, George]</td>\n",
       "      <td>[McDougall, Alexander]</td>\n",
       "      <td>1779-05-20</td>\n",
       "      <td>1779-05-20</td>\n",
       "      <td>Head Quarters Middle Brook May 20th 1779\\nDr S...</td>\n",
       "      <td>[0.0034233045, 0.039196797, 0.052478287, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>From Thomas Jefferson to João, Prince Regent o...</td>\n",
       "      <td>https://founders.archives.gov/documents/Jeffer...</td>\n",
       "      <td>Jefferson Papers</td>\n",
       "      <td>[Jefferson, Thomas]</td>\n",
       "      <td>[João, Prince Regent of Portugal]</td>\n",
       "      <td>1801-10-12</td>\n",
       "      <td>1801-10-12</td>\n",
       "      <td>To our Great and Good Friend, His Royal Highne...</td>\n",
       "      <td>[-0.06296448, 0.11988704, 0.08545797, -0.05848...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Thomas Jefferson to Joseph Milligan, 22 Decemb...   \n",
       "1    To Alexander Hamilton from James McHenry, 3 Ma...   \n",
       "2    John Adams to John Quincy Adams and Thomas Boy...   \n",
       "3    From George Washington to Major General Horati...   \n",
       "4                           [Diary entry: 5 July 1795]   \n",
       "..                                                 ...   \n",
       "995  From John Adams to Boston Patriot, 4 November ...   \n",
       "996  From John Adams to United States Senate, 14 Ma...   \n",
       "997  To Benjamin Franklin from William Henly, [Apri...   \n",
       "998  From George Washington to Major General Alexan...   \n",
       "999  From Thomas Jefferson to João, Prince Regent o...   \n",
       "\n",
       "                                             permalink            project  \\\n",
       "0    https://founders.archives.gov/documents/Jeffer...   Jefferson Papers   \n",
       "1    https://founders.archives.gov/documents/Hamilt...    Hamilton Papers   \n",
       "2    https://founders.archives.gov/documents/Adams/...       Adams Papers   \n",
       "3    https://founders.archives.gov/documents/Washin...  Washington Papers   \n",
       "4    https://founders.archives.gov/documents/Washin...  Washington Papers   \n",
       "..                                                 ...                ...   \n",
       "995  https://founders.archives.gov/documents/Adams/...       Adams Papers   \n",
       "996  https://founders.archives.gov/documents/Adams/...       Adams Papers   \n",
       "997  https://founders.archives.gov/documents/Frankl...    Franklin Papers   \n",
       "998  https://founders.archives.gov/documents/Washin...  Washington Papers   \n",
       "999  https://founders.archives.gov/documents/Jeffer...   Jefferson Papers   \n",
       "\n",
       "                  authors                                    recipients  \\\n",
       "0     [Jefferson, Thomas]                            [Milligan, Joseph]   \n",
       "1        [McHenry, James]                         [Hamilton, Alexander]   \n",
       "2           [Adams, John]  [Adams, John Quincy, Adams, Thomas Boylston]   \n",
       "3    [Washington, George]                              [Gates, Horatio]   \n",
       "4    [Washington, George]                                            []   \n",
       "..                    ...                                           ...   \n",
       "995         [Adams, John]                              [Boston Patriot]   \n",
       "996         [Adams, John]                        [United States Senate]   \n",
       "997      [Henly, William]                          [Franklin, Benjamin]   \n",
       "998  [Washington, George]                        [McDougall, Alexander]   \n",
       "999   [Jefferson, Thomas]             [João, Prince Regent of Portugal]   \n",
       "\n",
       "      date-from     date-to  \\\n",
       "0    1815-12-22  1815-12-22   \n",
       "1    1791-05-03  1791-05-03   \n",
       "2    1794-09-14  1794-09-14   \n",
       "3    1776-12-23  1776-12-23   \n",
       "4    1795-07-05  1795-07-05   \n",
       "..          ...         ...   \n",
       "995  1809-11-04  1809-11-04   \n",
       "996  1798-03-14  1798-03-14   \n",
       "997  1772-04-01  1772-04-30   \n",
       "998  1779-05-20  1779-05-20   \n",
       "999  1801-10-12  1801-10-12   \n",
       "\n",
       "                                               content  \\\n",
       "0    Monticello Dec. 22. 15.\\nDear Sir\\nOn my retur...   \n",
       "1    [Baltimore] 3 May 1791.\\nMy dear Sir.\\nI did n...   \n",
       "2    Quincy Septr.14. 1794\\nMy dear Sons\\nI once mo...   \n",
       "3    Head Quarters [Bucks County, Pa.] 23d Decr 177...   \n",
       "4                      Could not find the main content   \n",
       "..                                                 ...   \n",
       "995  Quincy, November 4, 1809.\\nSirs,\\nIn my last l...   \n",
       "996  United States March 14th 1798:\\nGentlemen of t...   \n",
       "997  Sunday Eve. [April?, 1772]\\nDear Sir:\\nI have ...   \n",
       "998  Head Quarters Middle Brook May 20th 1779\\nDr S...   \n",
       "999  To our Great and Good Friend, His Royal Highne...   \n",
       "\n",
       "                                             embedding  \n",
       "0    [-0.11585674, -0.031811118, 0.054534256, -0.04...  \n",
       "1    [-0.077039875, 0.06889965, 0.05614029, -0.0018...  \n",
       "2    [-0.13977431, 0.04176549, 0.06941472, -0.06869...  \n",
       "3    [0.006098511, 0.048442684, 0.046325486, -0.071...  \n",
       "4    [0.041819364, -0.009509875, -0.019032704, -0.0...  \n",
       "..                                                 ...  \n",
       "995  [-0.026789177, -0.004801429, 0.06341488, -0.11...  \n",
       "996  [-0.08672993, 0.036208663, 0.036546204, -0.038...  \n",
       "997  [-0.06445475, 0.060675066, 0.07255046, 0.07447...  \n",
       "998  [0.0034233045, 0.039196797, 0.052478287, -0.07...  \n",
       "999  [-0.06296448, 0.11988704, 0.08545797, -0.05848...  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e851e",
   "metadata": {},
   "source": [
    "At this stage, we now have all the data necessary to create a vector database! Before we do that, let's learn a little bit about vector databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ef40c3",
   "metadata": {},
   "source": [
    "# What are Vector Databases?\n",
    "\n",
    "Vector databases are specialized storage and retrieval systems designed to handle high-dimensional vector data efficiently. Unlike traditional databases that work with structured data like numbers and text, vector databases are optimized for managing and querying vector embeddings - numerical representations of data points in a multi-dimensional space.\n",
    "\n",
    "At their core, vector databases address the challenge of similarity search in large datasets. They excel at finding the most similar items to a given query, which is crucial for applications like recommendation systems, image recognition, and natural language processing. For instance, in a vector database storing product information, you could easily find similar products based on various attributes, all encoded as vectors.\n",
    "\n",
    "The key advantage of vector databases lies in their ability to perform fast approximate nearest neighbor (ANN) searches. Traditional databases might struggle with the \"curse of dimensionality\" when dealing with high-dimensional data, but vector databases employ specialized indexing techniques to maintain efficiency. This makes them particularly useful for AI and machine learning applications, where data is often represented in high-dimensional vector spaces.\n",
    "\n",
    "For those new to the concept, you can think of a vector database as a system that organizes information in a way that mirrors how our brains associate related concepts. Just as we can quickly recall words or images that are similar to a given prompt, vector databases can rapidly retrieve data points that are \"close\" to each other in a mathematical sense. This capability opens up exciting possibilities for creating more intelligent and intuitive data-driven applications across various domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6f1d8e",
   "metadata": {},
   "source": [
    "# BM25\n",
    "\n",
    "BM25 (Best Matching 25) is a ranking function used in information retrieval systems, particularly in search engines. It's an advanced form of TF-IDF (Term Frequency-Inverse Document Frequency) that provides a way to rank documents based on their relevance to a given search query.\n",
    "\n",
    "BM25 improves upon simpler ranking methods by incorporating document length normalization. This means it can account for the fact that longer documents are more likely to contain a given term simply due to their length, rather than because of relevance.\n",
    "\n",
    "The algorithm calculates a score for each document based on the query terms it contains. It considers both how often a term appears in a document (term frequency) and how rare the term is across all documents (inverse document frequency). However, it also applies a saturation function to prevent common terms from dominating the score.\n",
    "\n",
    "For those new to information retrieval, BM25 can be thought of as a way of determining which documents in a collection are most relevant to a user's search query. It's widely used in practice due to its effectiveness and relatively simple implementation.\n",
    "\n",
    "Now, let's look at how we can implement BM25 in Python using a DataFrame's content field.\n",
    "\n",
    "To do that, we first need to tokenize our text. To keep things simple for this notebook, we will just be using `split()`. Normally, you would use something more reliable, like spaCy's tokenizer and perform some basic data cleaning, such as removing punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "26c6c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_docs = [doc.split() for doc in df[\"content\"]]\n",
    "\n",
    "tokenized_docs = []\n",
    "for doc in df[\"content\"]:\n",
    "    split_doc = doc.split()\n",
    "    tokenized_docs.append(split_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e7abcd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Monticello', 'Dec.', '22.', '15.', 'Dear', 'Sir', 'On', 'my', 'return', 'here', 'from', 'Bedford', 'a', 'few', 'days', 'ago,', 'I', 'found', 'the', 'Hutton', 'and', 'Requisite', 'tables,', 'bound', 'to', 'my', 'mind.', 'by', 'this', 'mail', 'I', 'send', 'you', 'an', 'Ovid’s', 'metamorphoses', 'almost', 'entirely', 'worne', 'out', '&', 'defaced,', 'yet', 'of', 'sovaluable', 'and', 'rareaneditionthat', 'I', 'wish', 'you', 'to', 'put', 'it', 'into', 'as', 'good', 'a', 'state', 'of', 'repair', 'as', 'it', 'is', 'susceptible', 'of.', 'by', 'the', 'next', 'mail', 'I', 'will', 'forward', 'a', 'Cornelius', 'Nepos', 'to', 'be', 'bound.', 'be', 'so', 'good', 'as', 'to', 'procure', 'and', 'forward', 'to', 'me', 'by', 'stage', 'the', 'underwritten', 'books.I', 'salute', 'you', 'with', 'friendship', '&', 'esteem', 'Th:', 'Jefferson', 'Ainsworth’sLat.', '&', 'Eng.', 'dict.', 'abridged.', 'to', 'be', 'bound[.', '.', '.]', 'the', 'Lat.', '&', 'Eng', 'in', 'one,', '&', 'the', 'Eng.', '&', 'Lat.[.', '.', '.]', 'Ovid’s', 'metamorphoses.', 'the', 'Delphin', 'edn', 'in', '8vo', 'Cornelius', 'Nepos.', 'the', 'Delphin', 'edn', 'if', 'to', 'be', 'had;', 'if', 'not', 'some', 'other', 'good', 'one.', 'Virgil.', 'the', 'Delphin', 'edn', 'lately', 'printed', 'in', 'Phil.', 'with', 'English', 'notes.', 'Mair’s', 'Tyro’s', 'dictionary.', 'I', 'observe', 'a', 'mrRichardsonadvertises', 'in', 'the', 'National', 'Intelligencer', 'the', 'Scientific', 'dialogues:', 'if', 'the', 'edition', 'be', 'compleat', 'comprehending', 'theChemical', 'part,', 'I', 'should', 'be', 'glad', 'to', 'have', 'it']]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_docs[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53829e94",
   "metadata": {},
   "source": [
    "As we can see, our documents have now been naively tokenzed. We can now past this list of lists to BM250kapi directly with a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "48e45bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_index = BM25Okapi(tokenized_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d4793",
   "metadata": {},
   "source": [
    "This has now created a BM25 index for us! At this stage, we have essentially created a search engine index. To query it, we need to create a query, tokenize the query, and then use the `get_scores()` method to retrieve the results. It's also best practice to sort these based on the scores. Finally, we can retrieve the results from the original DataFrame. In the cell below, we will have all the code necessary to perform these operations. I've done this so that you can more easily test this out with multiple queries. To understand what's happening in the code, though, let's breakdown each step here.\n",
    "\n",
    "## Query Definition and Tokenization\n",
    "\n",
    "```python\n",
    "query = \"war\"\n",
    "tokenized_query = query.split()\n",
    "```\n",
    "\n",
    "- `query = \"war\"`: This line defines the search query. In this case, we're searching for documents related to \"war\".\n",
    "- `tokenized_query = query.split()`: This line tokenizes the query string. The `split()` method without arguments splits the string on whitespace, creating a list of individual words. For our simple query, this results in `[\"war\"]`. For multi-word queries, it would separate each word.\n",
    "\n",
    "## Scoring Documents\n",
    "\n",
    "```python\n",
    "doc_scores = bm25_index.get_scores(tokenized_query)\n",
    "```\n",
    "\n",
    "- This line uses the pre-computed BM25 index (`bm25_index`) to score each document in the corpus based on the tokenized query.\n",
    "- `get_scores()` method calculates a relevance score for each document in relation to the query.\n",
    "- The result `doc_scores` is a list of floating-point numbers, where each number represents the relevance score of the corresponding document in the original corpus.\n",
    "\n",
    "## Ranking Documents\n",
    "\n",
    "```python\n",
    "ranked_docs = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)[:5]\n",
    "```\n",
    "\n",
    "- `enumerate(doc_scores)`: This creates pairs of (index, score) for each document.\n",
    "- `sorted(...)`: This sorts these pairs based on a specific key.\n",
    "- `key=lambda x: x[1]`: This lambda function tells `sorted()` to use the score (the second item in each pair) as the sorting key.\n",
    "- `reverse=True`: This sorts in descending order, so highest scores come first.\n",
    "- `[:5]`: This slices the result to get only the top 5 results.\n",
    "- The final `ranked_docs` is a list of tuples, where each tuple contains the document index and its score, sorted by score in descending order.\n",
    "\n",
    "## Printing Results\n",
    "\n",
    "```python\n",
    "print(f\"Search results for query: '{query}'\")\n",
    "print(\"------------------------------\", \"\\n\")\n",
    "for idx, score in ranked_docs:\n",
    "    print(f\"Score: {score:.4f} - {df['content'][idx]}\")\n",
    "    print(\"-------------\", \"\\n\")\n",
    "```\n",
    "\n",
    "- The first `print()` statement displays the search query.\n",
    "- The second `print()` creates a visual separator.\n",
    "- The `for` loop iterates over the `ranked_docs`:\n",
    "  - `idx` is the index of the document in the original DataFrame.\n",
    "  - `score` is the BM25 relevance score for that document.\n",
    "- Inside the loop:\n",
    "  - We print the score formatted to 4 decimal places.\n",
    "  - We retrieve and print the content of the document using `df['content'][idx]`.\n",
    "  - We print another separator between results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f7711",
   "metadata": {},
   "source": [
    "Spend a few minutes testing out different queries. What do you notice when you query `warfare`? What about `War` capitalized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "32761fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query: 'War'\n",
      "------------------------------ \n",
      "\n",
      "Score: 5.7643 - Havre de Grace June 17th 1800\n",
      "Sir\n",
      "My particular Situation will I trust plead my apology for this indirect channel of approach—Will you oblige me by directing the Secretary of War to suspend any operation upon my Letter of Resignation, addressed to Major General Pinckney, untill the arrival of Brigadier General Wilkinson, who is, I am informed, shortly expected in this quarter, or untill the state of my case shall have been candidly submitted to your observation—The Major General who has been apprised of my situation, writes me that my Letter is forwarded to the Secretary of War “to meet your final determination and pleasure”\n",
      "With sentiments of real personal respect I have the honor to be, Sir—your most Obedt Servt\n",
      "Campbell Smith\n",
      "------------- \n",
      "\n",
      "Score: 5.3324 - 17 August 1813, “War Office.” “D. Parker has the honor to inform the President of the United States that nothing of moment has been received at the War Office since his report of the situation of the fleets on lake Ontario.”\n",
      "------------- \n",
      "\n",
      "Score: 5.1388 - [Cambridge, 18 October 1775]\n",
      "At a Council of War held at Head Quarters October 18th 1775.\n",
      "The General acquainted the Members of the Council that he had called them together in Consequence of an Intimation from the Congress, that an Attack upon Boston if practicable was much desired. That he therefore desired their Opinion on this Subject.\n",
      "------------- \n",
      "\n",
      "Score: 5.1156 - [3 June 1814]\n",
      "J. Madison requests a consultation with the Heads of Department on Tuesday next at Eleven OClock.\n",
      "June 3. 1814.\n",
      "The object is to decide on the plan of campaign which our means, miltary & naval, render most eligible.\n",
      "In the mean time the Secretary of War will cause to be made out & send over,\n",
      "J.M.\n",
      "------------- \n",
      "\n",
      "Score: 5.0295 - § From James Leander Cathcart.26 April 1806, Georgetown.“It occurs to me that the Bashaw of Tunis has too much good sense to declare War against the United States while they have a force in the Mediterranean able to cope with his; in opposition to this opinion it may be stated that the United States having refused to comply with the Bashaws demand, of maratime & military stores, if receded from by him without his endeavoring to force our compliance, will form a precedent & be a powerful inducement to Denmark Sweden & Holland to follow the example, & the Bashaw will probably rather hazard a defensive War than run the risk of those Nations emulating ours; in this case he will keep his Cruisers in Port, & our efforts in the first instance ought to be to effect the destruction of his commerce, if our Squadron should be too much reduced, an offensive war will immediately take place, & his numerous Cruisers may get out & injure ours; should the Bashaw conceive it to be his interest to continue peace on the terms prescribed by Treaty he will naturally seek some pretext to palliate the measure to the Agents of other nations: his wounded pride independent of his interest will induce him to endeavor to make it be believ’d, that the United States intend to pay him occasional presents although they are averse to any stipulation on the subject of a permanent annuity & that we wish’d to be placed upon the same ground that Great Britain France & Spain are, whom to carry certain points have frequently made him presents: the articles contemplated to be sent as a present in return for those receiv’d by his Ambassador will furnish him with an opportunity to adopt this measure, for if he determines on Peace, their value will be enhanced ten fold; if on War depreciated in the same ratio, & probably he will refuse to accept them.\n",
      "“I therefore recommend as many packages to be made as possible, in order that the present may make some appearance should it be landed at Tunis; this may be done with a trifling additional expense, by adding to such articles as may be selected from the former list, some of those in the list hereunto annex’d.”\n",
      "Adds in a postscript: “The weather has prevented me from calling at your office this day according to promise, I will wait upon you on Monday.”\n",
      "------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"War\"\n",
    "tokenized_query = query.split()\n",
    "doc_scores = bm25_index.get_scores(tokenized_query)\n",
    "\n",
    "# Sort documents by score\n",
    "ranked_docs = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "# Print results\n",
    "print(f\"Search results for query: '{query}'\")\n",
    "print(\"------------------------------\", \"\\n\")\n",
    "for idx, score in ranked_docs:\n",
    "    print(f\"Score: {score:.4f} - {df['content'][idx]}\")\n",
    "    print(\"-------------\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3449d",
   "metadata": {},
   "source": [
    "# Creating a Vector Database\n",
    "\n",
    "Now that we have seen how to create a tradition text database and even learned to query it, let's compare these results to a vector database. To create our database, we will be using `Annoy` from Spotify. Annoy is a nearest neighbor algorithm that allows for us to easily and efficiently store millions of vectors in an index that we can then retrieve very efficiently. This is achieved by using a computationally efficient algorithm that is written in C. To use annoy, we first need to know the dimensions of our vectors. We can use `.shape` and examine index 1 to get our vector dimensions. Note, these will change from model to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34c2cbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_dim = embeddings.shape[1]\n",
    "vector_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2877dfd4",
   "metadata": {},
   "source": [
    "As we can see, we have a dimension of 384. Now that we know that, we can create our index which we will populate with vectors. When creating an AnnoyIndex, we need to specify two things: the number of vectors and the way in which want to measure similarity. We have a few options here. We are using `angular`.\n",
    "\n",
    "```\n",
    "AnnoyIndex(f, metric) returns a new index that's read-write and stores vector of f dimensions. Metric can be \"angular\", \"euclidean\", \"manhattan\", \"hamming\", or \"dot\". - Annoy docs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "24d2f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "annoy_index = AnnoyIndex(vector_dim, 'angular')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361c1ee",
   "metadata": {},
   "source": [
    "Now that we have created our index, it's time to populate it with data. When we do this, e need to use the `add_item()` method. This will take two arguments: the index number and the embedding itself. We can use `enumerate()` to create our `i` variable that will tick up by one each time we loop over our data. This is the equivalent of doing `i=i+1` inside our loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0e1f0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add items to the index\n",
    "for i, embedding in enumerate(embeddings):\n",
    "    annoy_index.add_item(i, embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8c81ac",
   "metadata": {},
   "source": [
    "At this stage, our index has the data but it is not yet built. To build it, we can use the `build()` method. This will take 1 argument, the number of trees we want to use. In theory, the more trees, the better, but there's a point where you have diminished returns. Unless you are working with very complex data, `10` is usually a good starting number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b3aa74ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annoy_index.build(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389fd59f",
   "metadata": {},
   "source": [
    "Now that we have our index built, we can query it. Again, I'll write all the code in a single cell and explain it row by row in markdown.\n",
    "\n",
    "## Query Definition and Encoding\n",
    "\n",
    "```python\n",
    "query = \"warfare\"\n",
    "query_vector = model.encode(query)\n",
    "```\n",
    "\n",
    "- `query = \"warfare\"`: This line defines the search query. We're searching for documents related to \"warfare\".\n",
    "- `query_vector = model.encode(query)`: This line uses a pre-trained model (likely a sentence transformer) to encode the query into a vector. The `encode()` method transforms the text query into a high-dimensional numerical vector that represents its semantic meaning.\n",
    "\n",
    "## Searching the Annoy Index\n",
    "\n",
    "```python\n",
    "similar_item_ids = annoy_index.get_nns_by_vector(query_vector, 5)\n",
    "```\n",
    "\n",
    "- `annoy_index`: This is a pre-built Annoy (Approximate Nearest Neighbors Oh Yeah) index, which allows for efficient similarity search in vector space.\n",
    "- `get_nns_by_vector(query_vector, 5)`: This method searches the Annoy index for the 5 nearest neighbors to our query vector.\n",
    "  - The first argument is our encoded query vector.\n",
    "  - The second argument (5) specifies that we want the top 5 most similar items.\n",
    "- `similar_item_ids`: This variable stores the indices of the 5 most similar items found in the index.\n",
    "\n",
    "## Retrieving Results from DataFrame\n",
    "\n",
    "```python\n",
    "df.iloc[similar_item_ids]\n",
    "```\n",
    "\n",
    "- This line uses the indices returned by Annoy to fetch the corresponding rows from our DataFrame `df`.\n",
    "- `iloc[]` is used for integer-location based indexing.\n",
    "- The result is a new DataFrame containing only the rows that match our search results.\n",
    "\n",
    "## Printing Results\n",
    "\n",
    "```python\n",
    "print(f\"Search results for query: '{query}'\")\n",
    "print(\"------------------------------\", \"\\n\")\n",
    "for i, result in enumerate(df.iloc[similar_item_ids].content.tolist()):\n",
    "    print(f\"Result {i}\")\n",
    "    print(result.replace(\"\\n\", \"\\n\\n\"))\n",
    "    print(\"--------\")\n",
    "```\n",
    "\n",
    "- The first `print()` statement displays the search query.\n",
    "- The second `print()` creates a visual separator.\n",
    "- `df.iloc[similar_item_ids].content.tolist()`: This gets the 'content' column from our result rows and converts it to a list.\n",
    "- The `for` loop iterates over this list of content:\n",
    "  - `enumerate()` is used to get both the index and the content of each result.\n",
    "  - `i` is the index (0-4 for our 5 results).\n",
    "  - `result` is the content of each matching document.\n",
    "- Inside the loop:\n",
    "  - We print the result number.\n",
    "  - We print the content, replacing single newlines with double newlines for better readability.\n",
    "  - We print a separator between results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7f03fbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query: 'warfare'\n",
      "------------------------------ \n",
      "\n",
      "Result 0\n",
      "In Council16th. Novem: 1782.\n",
      "\n",
      "Gentlemen\n",
      "\n",
      "I have your favor by the last post, and think with you that it is problematical whether the British quit Charles Town or not, tho’ on the 25th. of last Month they had made such advances towards it that hopes are to be entertain’d of their being embarked before the countermanding orders arrive. If this should be the case, & they still entertain hopes of conquest in America may they not call on us, if they should, we were never less prepared, some demon or other certainly possessed us when we disposed of the ships that were prepared to bring over the arms & ammunition from France, both which are now so much wanted that if you do not think it improper you will do your Country a great Service by again pressing the Chevilier to use his Interest to have them brought over in a Frigate. The Scarcity of musket powder is so great in the State owing to our losses by the Enemy, and the necessary consumption of it during the Invasion that an immediate supply is absolutely necessary, and as we have no means of obtaining it but thro’ Congress I request that you use your Endeavours to procure from them three or four Tuns, that they owe us so much is beyond a doubt, but if you can not obtain it in return for what we have expended, rather than be disappointed I would take it on account till our demands can be adjusted. If you succeed please to send it on immediately in Waggons to Westham, which you know is not above six Miles from hence and is not much out of the way, the waggonage shall be certainly paid on their arrival. If you can’t procure it this way, perhaps it may be bought in the Town for Tobacco on Rappahannock or Powtamac rivers, to be paid on the delivery of the Powder, in which case you’l please to contract for it, and inform me immediately. the price we have fixed you have below, but if that can not be obtained, I know of no other Mode of doing Justice to the State & the Seller but by having it fixed by the agent for commutables here & a Merchant of reputation oneither of those rivers chosen by the Seller. No business of consequence is yet done by the Assembly.\n",
      "\n",
      "I am &c.\n",
      "\n",
      "B. H.\n",
      "--------\n",
      "Result 1\n",
      "§ From James Leander Cathcart.26 April 1806, Georgetown.“It occurs to me that the Bashaw of Tunis has too much good sense to declare War against the United States while they have a force in the Mediterranean able to cope with his; in opposition to this opinion it may be stated that the United States having refused to comply with the Bashaws demand, of maratime & military stores, if receded from by him without his endeavoring to force our compliance, will form a precedent & be a powerful inducement to Denmark Sweden & Holland to follow the example, & the Bashaw will probably rather hazard a defensive War than run the risk of those Nations emulating ours; in this case he will keep his Cruisers in Port, & our efforts in the first instance ought to be to effect the destruction of his commerce, if our Squadron should be too much reduced, an offensive war will immediately take place, & his numerous Cruisers may get out & injure ours; should the Bashaw conceive it to be his interest to continue peace on the terms prescribed by Treaty he will naturally seek some pretext to palliate the measure to the Agents of other nations: his wounded pride independent of his interest will induce him to endeavor to make it be believ’d, that the United States intend to pay him occasional presents although they are averse to any stipulation on the subject of a permanent annuity & that we wish’d to be placed upon the same ground that Great Britain France & Spain are, whom to carry certain points have frequently made him presents: the articles contemplated to be sent as a present in return for those receiv’d by his Ambassador will furnish him with an opportunity to adopt this measure, for if he determines on Peace, their value will be enhanced ten fold; if on War depreciated in the same ratio, & probably he will refuse to accept them.\n",
      "\n",
      "“I therefore recommend as many packages to be made as possible, in order that the present may make some appearance should it be landed at Tunis; this may be done with a trifling additional expense, by adding to such articles as may be selected from the former list, some of those in the list hereunto annex’d.”\n",
      "\n",
      "Adds in a postscript: “The weather has prevented me from calling at your office this day according to promise, I will wait upon you on Monday.”\n",
      "--------\n",
      "Result 2\n",
      "Philadelphia Jany 26th[–30] 1780\n",
      "\n",
      "sir\n",
      "\n",
      "Being arrived here on the night of Saturday the 22d Inst. I delivered next Day Early in the morning Your Excellency’s Letter to the President of Congress, & I am informed but to day that the Board of War is charged to Confer with me on the present State of the Army.\n",
      "\n",
      "I do not know as yet what this Conference will tend to, There is a talk of a Committee being to repair to Camp, in Order to give a new formation to our Army; It is Spoken likewise of incorporating 41 Regiments, but I really believe that nothing is yet determined upon this Subject.\n",
      "\n",
      "The Minister of France has communicated to me that he is on the point of asking of Congress what means they intend to Employ for the Operations of the next Campaign, that he may give notice to his Court & to the Chiefs of Squadrons to make their Arrangements in Consequence.\n",
      "\n",
      "He has given me certain Assurances that We may reckon on the Arrival of a French Fleet upon our Coast, in case We are able to Cooperate on our Side.\n",
      "\n",
      "He has told me he has sent his Opinion to Your Excellency on the Subject of the Cartel proposed by the Enemy.\n",
      "\n",
      "I have just received an Order from the Board of War, to attend at their Office to morrow at 6 o’clock.P.M.\n",
      "\n",
      "Several Gentlemen in Congress, & Especially the Eastern Members appear Extremely well disposed to reinforce the Army for next Campaign, & to do all in their Power to promote Vigorous Operations. there are indeed, different Schemes proposed, but I shall not contradict any, provided We have an Army.\n",
      "\n",
      "I have delivered to the Board of War, the Returns of the Infantry, & as far as I could, I have acquainted them with the state of our Army. I Am desired to give my Opinion without delay of the Preparations that are to be made for next Campaign.\n",
      "\n",
      "I delivered Yesterday to the Board of War the annexed Memorial. It is only a General Calculation which requires a more Exact Examination.\n",
      "\n",
      "The Hon. Mr Livingston, a Member of Congress, was deputed on their part to the Board, he communicated the Answer of Your Excellency on the scheme of incorporating the Regiments.\n",
      "\n",
      "If any thing should induce me to advise an Incorporation it would be the Vacancies of Officers, which I know not how We are to fill. I fear, however, it will produce a great deal of discontent, & other ill Consequences.\n",
      "\n",
      "Mr Peters proposed to put off all Arrangement, & to consider in this moment only the number of Men which the respective states are to furnish for the next Campaign.\n",
      "\n",
      "The number of Infantry which I have proposed in my Memorial was admitted, I represented however that it would be necessary to reckon on 40 Men more ⅌ Regiment, on account of the diminution which may happen from this Time to the beginning of next Campaign.\n",
      "\n",
      "Mr Livingston objected against the number of Cavalry which I proposed, on account of the impossibility of mounting it. This Consideration was however suspended, not to defer the Calculation of the Men only.\n",
      "\n",
      "I have received an Order from the Board of War to procure without delay the Returns, the List of which is here Enclosed.\n",
      "\n",
      "I beg, Sir, You will interpose Your Authority that these Returns may be transmitted immediately.\n",
      "\n",
      "It appears indispensably necessary to prohibit the distribution of the Arms, Cartridges &c. till the Quantity now in the Regiments & Magazines is well known & ascertained.\n",
      "\n",
      "I beg, dear General, You will let me know your Opinion of the proportion for an Army which you will find in my Memorial, as I wish to act solely by Your Excellency’s Direction. Be pleased, Sir, to honor me with your Confidence, & be assured that my Zeal for the service can only be Equalled by the profound respect with which I have the honor to be sir, Your Excellency’s Most obedient and Very humble servant\n",
      "\n",
      "steuben\n",
      "--------\n",
      "Result 3\n",
      "Stanwick Novr 13th 1782\n",
      "\n",
      "Sir\n",
      "\n",
      "I have enclosed for Your Excellency the reports of several Persons who have been into N.Y. for the purpose of obtaining Intelligence—I expect very shortly to hear from C. & others, whose information will be duly forwarded.\n",
      "\n",
      "In addition to the enclosed, I am informed by a person from the Spot, that Col. Thompsons Corps are preparing Quarters at Huntington for the Winter, & they will not probably move farther Eastward unless for the purpose of Collecting forage. They are Erecting some Works for their Defence thro’ the Winter, at the East End of the Town, & near these posts the Troops are to be cantoned—The Infantry of the Regt which laid at & nearCold Springhave removed to Huntington—Some of the Militia have been called on to assist in building the Works—From the present position of the Enemy, altho’ they have not taken the Station first intended at Smith Town, I cannot but believe an Enterprise might be Conducted against that Corps, with success—The naval Guard in Huntington Harbour consists of only one Briga., a Sloop, & two Small Gallies—But in a still night, I think we should have little to fear from them. I shall be olbiged to attend the County Court at Fairfield on Tuesday next the 19th inst., when I shall depend on having the particular of Thompson’s present Situation accurately delineated. Tho’ Your Excellency was pleased to encourage an Attempt against that Corps under Circumstances which were then expected to take place, Yet I should be happy to know whether on the Ground which he now occupies, Your Excellency would suppose the Attempt still adviseable. If so I will exert myself to obtain a plan of the Works & Defences preparing at that place, with other information necessary, & lay them before Your Excellency. A Party of horse have been Eastward on Long Island, & demanded one half of all the Forage, which the Inhabitants are ordered to transport to Huntington. I have the Honor to be, With great Regard, Sir, Your Excellency’s most Obedt Servt\n",
      "\n",
      "Benja. Tallmadge\n",
      "--------\n",
      "Result 4\n",
      "Skippack Camp [Pa.] 11th Octor 1777\n",
      "\n",
      "Sir\n",
      "\n",
      "I rec’d yours of the 19th informing of the occasion of the late firing. I imagine the Enemy still persist in their attempt as the firing has continued by intervals ever since. As the rear of the Fort is only defended by a picket work, I think you ought to lose no time in throwing up a Bank against the picket which wou’d strengthen it and make it defensible against shot. If some blinds were thrown up within the Area of the Fort they wou’d be a security against Shells of which I think you are in more danger than from Shot. you seem apprehensive if the Enemy possess province Island, that your Men must quit their Barracks in that case you should think of finding out some more secure place of Sheltering them. I cannot at present think of any place better than between the East face of the stone Fort and the lower Battery, they will at leastbe safe there untill an attack begins from the water. I desir’d Capt. Blewer who went from hence yesterday, to caution the Commodore against an unnecessary expenditure of ammunition and beg that you woud also be careful in that point, for should the Enemy cut off your intercourse with us, you will find the want of it. I am Sir your most Obet Servt\n",
      "\n",
      "G. W——n\n",
      "\n",
      "P.S. Should the Enemy get Possession of the Ground near the Pest Houses what effect wou’d their fire have upon Shipping? If this ground would be advantageous to us do you think part of your Garrison, part of that intended for Red Bank, and some Militia from Jersey could possess & defend it? It is my wish that Colo. Green & you in concert with the Gentn of the Navy, would turn your attention to every place which will contribute to the defence of the Water obstructions, & if it is in my Power to afford assistance, I will do it.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "query = \"warfare\"\n",
    "query_vector = model.encode(query)\n",
    "similar_item_ids = annoy_index.get_nns_by_vector(query_vector, 5)\n",
    "df.iloc[similar_item_ids]\n",
    "print(f\"Search results for query: '{query}'\")\n",
    "print(\"------------------------------\", \"\\n\")\n",
    "for i, result in enumerate(df.iloc[similar_item_ids].content.tolist()):\n",
    "    print(f\"Result {i}\")\n",
    "    print(result.replace(\"\\n\", \"\\n\\n\"))\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08743c56",
   "metadata": {},
   "source": [
    "Notice that using `warfare` here, returns results similar to warfare. This is because we are querying the dataset by vectors, rather than keywords. This means the word `warfare` does not have to appear in order to get results. Unfortunately, this can make the results (especially longer documents) difficult to understand. What specifically in the text is giving us the result. Vectors can also dilute the document. Maybe the document speaks about warfare, but only in a very specific region while the rest of it speaks of farming. How do we handle problems like this? The answer comes down to chunking our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc704fa",
   "metadata": {},
   "source": [
    "# Chunking\n",
    "\n",
    "We have many ways to chunk our data: character-level, token-level, sentence-level, paragraph-level etc. For most vector databases, sentence-level chunking works best. This is because sentences function a syntactic and discrete unit in a text. Unlike paragraphs, sentences are formatted across texts the same way in a given language. In English we use `.` to represent the end of a distinct sentence. In chunking, we take an input document and break it into smaller chunks.\n",
    "\n",
    "We have two ways to perform this process as a sliding window with or without overlap. Overlap is the degree to which the next item overlaps with the previous. Let's assume we have 9 sentences in our document, labeled from sentence1 to sentence9. We'll demonstrate how chunking works with different levels of overlap.\n",
    "\n",
    "## No Overlap\n",
    "\n",
    "With no overlap and a chunk size of 3, our chunks would look like this:\n",
    "\n",
    "chunk1: [sentence1, sentence2, sentence3]\n",
    "chunk2: [sentence4, sentence5, sentence6]\n",
    "chunk3: [sentence7, sentence8, sentence9]\n",
    "\n",
    "## Overlap of 1\n",
    "\n",
    "Now, let's see how it looks with an overlap of 1:\n",
    "\n",
    "chunk1: [sentence1, sentence2, sentence3]\n",
    "chunk2: [sentence3, sentence4, sentence5]\n",
    "chunk3: [sentence5, sentence6, sentence7]\n",
    "chunk4: [sentence7, sentence8, sentence9]\n",
    "\n",
    "## Overlap of 2\n",
    "\n",
    "Finally, here's how it would look with an overlap of 2:\n",
    "\n",
    "chunk1: [sentence1, sentence2, sentence3]\n",
    "chunk2: [sentence2, sentence3, sentence4]\n",
    "chunk3: [sentence3, sentence4, sentence5]\n",
    "chunk4: [sentence4, sentence5, sentence6]\n",
    "chunk5: [sentence5, sentence6, sentence7]\n",
    "chunk6: [sentence6, sentence7, sentence8]\n",
    "chunk7: [sentence7, sentence8, sentence9]\n",
    "\n",
    "In this last example with an overlap of 2, each chunk (except the first) includes the two previous sentences along with a new sentence. This creates a sliding window effect where each chunk shares a significant amount of content with its neighboring chunks, potentially preserving more context and continuity in the chunked data.\n",
    "\n",
    "The choice of chunk size and overlap depends on the specific requirements of your application. A larger chunk size with some overlap can help maintain context across chunks, which can be beneficial for tasks that require understanding broader context. However, it also increases the number of chunks, which can impact processing time and storage requirements.\n",
    "\n",
    "To chunk our data into sentences, we'll first need to separate the text into sentences. To do that, we will use spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4fbd8c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/tap/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x3c6322800>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266cea74",
   "metadata": {},
   "source": [
    "With this pipeline we can now chunk our data. In the cell below, we will be creating a new dataset from our original one while preserving the original index (document) index. This is so that we can make our chunks to the original data. We can also preserve the subindex for each chunk within the document. This means that for any given index in our chunked data, we have access to its position within the document to which it belongs and the corpus as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5096be7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking texts: 100%|██████████| 1000/1000 [00:01<00:00, 800.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to chunk text into groups of 3 sentences\n",
    "def chunk_text(text, chunk_size=3):\n",
    "    doc = nlp(text)\n",
    "    sentences = list(doc.sents)\n",
    "    chunks = []\n",
    "    for i in range(0, len(sentences), chunk_size):\n",
    "        chunk = sentences[i:i+chunk_size]\n",
    "        chunks.append(\" \".join([sent.text for sent in chunk]))\n",
    "    return chunks\n",
    "\n",
    "# Create chunks\n",
    "chunked_data = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Chunking texts\"):\n",
    "    chunks = chunk_text(row['content'])\n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        chunk_data = row.to_dict()\n",
    "        chunk_data['content'] = chunk\n",
    "        chunk_data['document_index'] = idx\n",
    "        chunk_data['chunk_index'] = chunk_idx\n",
    "        chunked_data.append(chunk_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe3ba8",
   "metadata": {},
   "source": [
    "Once chunked, we can then create a new dataset with our chunked data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "44fe9ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>permalink</th>\n",
       "      <th>project</th>\n",
       "      <th>authors</th>\n",
       "      <th>recipients</th>\n",
       "      <th>date-from</th>\n",
       "      <th>date-to</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "      <th>document_index</th>\n",
       "      <th>chunk_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thomas Jefferson to Joseph Milligan, 22 Decemb...</td>\n",
       "      <td>https://founders.archives.gov/documents/Jeffer...</td>\n",
       "      <td>Jefferson Papers</td>\n",
       "      <td>[Jefferson, Thomas]</td>\n",
       "      <td>[Milligan, Joseph]</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>Monticello Dec. 22. 15. \\nDear Sir\\nOn my retu...</td>\n",
       "      <td>[-0.11585661, -0.031811137, 0.05453429, -0.047...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thomas Jefferson to Joseph Milligan, 22 Decemb...</td>\n",
       "      <td>https://founders.archives.gov/documents/Jeffer...</td>\n",
       "      <td>Jefferson Papers</td>\n",
       "      <td>[Jefferson, Thomas]</td>\n",
       "      <td>[Milligan, Joseph]</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>by this mail I send you an Ovid’s metamorphose...</td>\n",
       "      <td>[-0.11585661, -0.031811137, 0.05453429, -0.047...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas Jefferson to Joseph Milligan, 22 Decemb...</td>\n",
       "      <td>https://founders.archives.gov/documents/Jeffer...</td>\n",
       "      <td>Jefferson Papers</td>\n",
       "      <td>[Jefferson, Thomas]</td>\n",
       "      <td>[Milligan, Joseph]</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>I salute you with friendship &amp; esteem\\nTh: Jef...</td>\n",
       "      <td>[-0.11585661, -0.031811137, 0.05453429, -0.047...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thomas Jefferson to Joseph Milligan, 22 Decemb...</td>\n",
       "      <td>https://founders.archives.gov/documents/Jeffer...</td>\n",
       "      <td>Jefferson Papers</td>\n",
       "      <td>[Jefferson, Thomas]</td>\n",
       "      <td>[Milligan, Joseph]</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>abridged. to be bound[. . .] \\nthe Lat. &amp;</td>\n",
       "      <td>[-0.11585661, -0.031811137, 0.05453429, -0.047...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas Jefferson to Joseph Milligan, 22 Decemb...</td>\n",
       "      <td>https://founders.archives.gov/documents/Jeffer...</td>\n",
       "      <td>Jefferson Papers</td>\n",
       "      <td>[Jefferson, Thomas]</td>\n",
       "      <td>[Milligan, Joseph]</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>1815-12-22</td>\n",
       "      <td>Eng in one, &amp; the Eng. &amp; Lat.[. . .] \\nOvid’s ...</td>\n",
       "      <td>[-0.11585661, -0.031811137, 0.05453429, -0.047...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>To Benjamin Franklin from William Henly, [Apri...</td>\n",
       "      <td>https://founders.archives.gov/documents/Frankl...</td>\n",
       "      <td>Franklin Papers</td>\n",
       "      <td>[Henly, William]</td>\n",
       "      <td>[Franklin, Benjamin]</td>\n",
       "      <td>1772-04-01</td>\n",
       "      <td>1772-04-30</td>\n",
       "      <td>Believe me Dear Sir to be with real regard you...</td>\n",
       "      <td>[-0.064454764, 0.060675174, 0.072550446, 0.074...</td>\n",
       "      <td>997</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>From George Washington to Major General Alexan...</td>\n",
       "      <td>https://founders.archives.gov/documents/Washin...</td>\n",
       "      <td>Washington Papers</td>\n",
       "      <td>[Washington, George]</td>\n",
       "      <td>[McDougall, Alexander]</td>\n",
       "      <td>1779-05-20</td>\n",
       "      <td>1779-05-20</td>\n",
       "      <td>Head Quarters Middle Brook May 20th 1779\\nDr S...</td>\n",
       "      <td>[0.0034233108, 0.03919683, 0.05247831, -0.0776...</td>\n",
       "      <td>998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>From Thomas Jefferson to João, Prince Regent o...</td>\n",
       "      <td>https://founders.archives.gov/documents/Jeffer...</td>\n",
       "      <td>Jefferson Papers</td>\n",
       "      <td>[Jefferson, Thomas]</td>\n",
       "      <td>[João, Prince Regent of Portugal]</td>\n",
       "      <td>1801-10-12</td>\n",
       "      <td>1801-10-12</td>\n",
       "      <td>To our Great and Good Friend, His Royal Highne...</td>\n",
       "      <td>[-0.062964484, 0.11988714, 0.085458025, -0.058...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>From Thomas Jefferson to João, Prince Regent o...</td>\n",
       "      <td>https://founders.archives.gov/documents/Jeffer...</td>\n",
       "      <td>Jefferson Papers</td>\n",
       "      <td>[Jefferson, Thomas]</td>\n",
       "      <td>[João, Prince Regent of Portugal]</td>\n",
       "      <td>1801-10-12</td>\n",
       "      <td>1801-10-12</td>\n",
       "      <td>Whilst under this mournful visitation we mingl...</td>\n",
       "      <td>[-0.062964484, 0.11988714, 0.085458025, -0.058...</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4566</th>\n",
       "      <td>From Thomas Jefferson to João, Prince Regent o...</td>\n",
       "      <td>https://founders.archives.gov/documents/Jeffer...</td>\n",
       "      <td>Jefferson Papers</td>\n",
       "      <td>[Jefferson, Thomas]</td>\n",
       "      <td>[João, Prince Regent of Portugal]</td>\n",
       "      <td>1801-10-12</td>\n",
       "      <td>1801-10-12</td>\n",
       "      <td>day of October in the Year of Our Lord One tho...</td>\n",
       "      <td>[-0.062964484, 0.11988714, 0.085458025, -0.058...</td>\n",
       "      <td>999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4567 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     Thomas Jefferson to Joseph Milligan, 22 Decemb...   \n",
       "1     Thomas Jefferson to Joseph Milligan, 22 Decemb...   \n",
       "2     Thomas Jefferson to Joseph Milligan, 22 Decemb...   \n",
       "3     Thomas Jefferson to Joseph Milligan, 22 Decemb...   \n",
       "4     Thomas Jefferson to Joseph Milligan, 22 Decemb...   \n",
       "...                                                 ...   \n",
       "4562  To Benjamin Franklin from William Henly, [Apri...   \n",
       "4563  From George Washington to Major General Alexan...   \n",
       "4564  From Thomas Jefferson to João, Prince Regent o...   \n",
       "4565  From Thomas Jefferson to João, Prince Regent o...   \n",
       "4566  From Thomas Jefferson to João, Prince Regent o...   \n",
       "\n",
       "                                              permalink            project  \\\n",
       "0     https://founders.archives.gov/documents/Jeffer...   Jefferson Papers   \n",
       "1     https://founders.archives.gov/documents/Jeffer...   Jefferson Papers   \n",
       "2     https://founders.archives.gov/documents/Jeffer...   Jefferson Papers   \n",
       "3     https://founders.archives.gov/documents/Jeffer...   Jefferson Papers   \n",
       "4     https://founders.archives.gov/documents/Jeffer...   Jefferson Papers   \n",
       "...                                                 ...                ...   \n",
       "4562  https://founders.archives.gov/documents/Frankl...    Franklin Papers   \n",
       "4563  https://founders.archives.gov/documents/Washin...  Washington Papers   \n",
       "4564  https://founders.archives.gov/documents/Jeffer...   Jefferson Papers   \n",
       "4565  https://founders.archives.gov/documents/Jeffer...   Jefferson Papers   \n",
       "4566  https://founders.archives.gov/documents/Jeffer...   Jefferson Papers   \n",
       "\n",
       "                   authors                         recipients   date-from  \\\n",
       "0      [Jefferson, Thomas]                 [Milligan, Joseph]  1815-12-22   \n",
       "1      [Jefferson, Thomas]                 [Milligan, Joseph]  1815-12-22   \n",
       "2      [Jefferson, Thomas]                 [Milligan, Joseph]  1815-12-22   \n",
       "3      [Jefferson, Thomas]                 [Milligan, Joseph]  1815-12-22   \n",
       "4      [Jefferson, Thomas]                 [Milligan, Joseph]  1815-12-22   \n",
       "...                    ...                                ...         ...   \n",
       "4562      [Henly, William]               [Franklin, Benjamin]  1772-04-01   \n",
       "4563  [Washington, George]             [McDougall, Alexander]  1779-05-20   \n",
       "4564   [Jefferson, Thomas]  [João, Prince Regent of Portugal]  1801-10-12   \n",
       "4565   [Jefferson, Thomas]  [João, Prince Regent of Portugal]  1801-10-12   \n",
       "4566   [Jefferson, Thomas]  [João, Prince Regent of Portugal]  1801-10-12   \n",
       "\n",
       "         date-to                                            content  \\\n",
       "0     1815-12-22  Monticello Dec. 22. 15. \\nDear Sir\\nOn my retu...   \n",
       "1     1815-12-22  by this mail I send you an Ovid’s metamorphose...   \n",
       "2     1815-12-22  I salute you with friendship & esteem\\nTh: Jef...   \n",
       "3     1815-12-22          abridged. to be bound[. . .] \\nthe Lat. &   \n",
       "4     1815-12-22  Eng in one, & the Eng. & Lat.[. . .] \\nOvid’s ...   \n",
       "...          ...                                                ...   \n",
       "4562  1772-04-30  Believe me Dear Sir to be with real regard you...   \n",
       "4563  1779-05-20  Head Quarters Middle Brook May 20th 1779\\nDr S...   \n",
       "4564  1801-10-12  To our Great and Good Friend, His Royal Highne...   \n",
       "4565  1801-10-12  Whilst under this mournful visitation we mingl...   \n",
       "4566  1801-10-12  day of October in the Year of Our Lord One tho...   \n",
       "\n",
       "                                              embedding  document_index  \\\n",
       "0     [-0.11585661, -0.031811137, 0.05453429, -0.047...               0   \n",
       "1     [-0.11585661, -0.031811137, 0.05453429, -0.047...               0   \n",
       "2     [-0.11585661, -0.031811137, 0.05453429, -0.047...               0   \n",
       "3     [-0.11585661, -0.031811137, 0.05453429, -0.047...               0   \n",
       "4     [-0.11585661, -0.031811137, 0.05453429, -0.047...               0   \n",
       "...                                                 ...             ...   \n",
       "4562  [-0.064454764, 0.060675174, 0.072550446, 0.074...             997   \n",
       "4563  [0.0034233108, 0.03919683, 0.05247831, -0.0776...             998   \n",
       "4564  [-0.062964484, 0.11988714, 0.085458025, -0.058...             999   \n",
       "4565  [-0.062964484, 0.11988714, 0.085458025, -0.058...             999   \n",
       "4566  [-0.062964484, 0.11988714, 0.085458025, -0.058...             999   \n",
       "\n",
       "      chunk_index  \n",
       "0               0  \n",
       "1               1  \n",
       "2               2  \n",
       "3               3  \n",
       "4               4  \n",
       "...           ...  \n",
       "4562            6  \n",
       "4563            0  \n",
       "4564            0  \n",
       "4565            1  \n",
       "4566            2  \n",
       "\n",
       "[4567 rows x 11 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new DataFrame with chunks\n",
    "chunked_df = pd.DataFrame(chunked_data)\n",
    "chunked_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f86babd",
   "metadata": {},
   "source": [
    "Unfortunately, though, our embeddings are precisely the same for each chunk. This isn't good. We want new embeddings for each chunk. Let's go ahead and repeat the steps from earlier in the notebook. This will take slightly longer as we now have ~4 times as many documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aca1cc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b420fdc3eab4753ba059ae9632fd5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vectorize the chunks\n",
    "chunks = chunked_df['content'].tolist()\n",
    "embeddings = model.encode(chunks, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b925dd",
   "metadata": {},
   "source": [
    "Now, let's go ahead and replace the original embeddings with our new ones!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "27d15d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add embeddings to the chunked DataFrame\n",
    "chunked_df['embedding'] = list(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb1aaa1",
   "metadata": {},
   "source": [
    "We will again repeat the same steps as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d6571af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annoy_index = AnnoyIndex(vector_dim, 'angular')\n",
    "# Add items to the index\n",
    "for i, embedding in enumerate(embeddings):\n",
    "    annoy_index.add_item(i, embedding)\n",
    "annoy_index.build(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a2f42",
   "metadata": {},
   "source": [
    "Let's again query our new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "836de64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query: 'warfare'\n",
      "------------------------------ \n",
      "\n",
      "Result 0\n",
      "an alliance offensive & defensive is concluded, & wh. embarks her in the war of course agnst. Engld.; &\n",
      "--------\n",
      "Result 1\n",
      "The Weapons employed in this War are law Suits, doors and locks and bolts. To neglect to employ these weapons is to forfeit those blessings. Nations in like manner can exist <on> with all the proragatives of nations only by War.\n",
      "--------\n",
      "Result 2\n",
      "Wars, among them. Captives. \n",
      "\n",
      "A Right to destroy them, if necessary to secure themselves.\n",
      "--------\n",
      "Result 3\n",
      "Id.\n",
      "\n",
      "1. to enter into war & peace with foreign powers 2 to enter into alliances with foreign powers and with one another, Not prejudicial to their engagements to the Empire Code d’Hum—3 to make laws, levy taxes, raisetroops, to determine on life & death. Savage.\n",
      "--------\n",
      "Result 4\n",
      "Painfull. Humanity, common Justice, and eternal Morality. \n",
      "\n",
      "Conquest and Rights of War.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "query = \"warfare\"\n",
    "query_vector = model.encode(query)\n",
    "similar_item_ids = annoy_index.get_nns_by_vector(query_vector, 5)\n",
    "chunked_df.iloc[similar_item_ids]\n",
    "print(f\"Search results for query: '{query}'\")\n",
    "print(\"------------------------------\", \"\\n\")\n",
    "for i, result in enumerate(chunked_df.iloc[similar_item_ids].content.tolist()):\n",
    "    print(f\"Result {i}\")\n",
    "    print(result.replace(\"\\n\", \"\\n\\n\"))\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a911ad55",
   "metadata": {},
   "source": [
    "Notice that our results are much more targeted. We only get results for a specific chunk of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d68c92",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
